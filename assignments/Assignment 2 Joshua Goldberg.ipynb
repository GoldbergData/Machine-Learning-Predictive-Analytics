{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Only use 'Salnty', 'STheta' for predictors (same as HW #1)\n",
    "2) Remove NaN / NA values from dataset (prior to building train/test sets) (same as HW 3) \n",
    "\n",
    "3) Scale all features to improve convergence. Feel free to use the sklearn tool \"StandardScaler\" - more info here: http://scikit-lear\n",
    "\n",
    "4) Try mini batch sizes of 50, 2000 and 10,000. Comment on the prediction accuracy base For the calculation of the gradient we will use partial derivative from the text. Pleas Example code from chapter:\n",
    "derived_gradient = 2/m * X_b.T.dot(X_b.dot(theta) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression as lm\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.preprocessing as preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle_df = pd.read_csv(\"bottle.csv\", low_memory=False)\n",
    "\n",
    "bottle_df.dropna(subset=[\"Salnty\", \"STheta\", \"T_degC\"], inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    bottle_df[[\"Salnty\", \"STheta\"]],\n",
    "    bottle_df[\"T_degC\"], test_size=.20,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "y_train = np.asarray(y_train).reshape((len(y_train), 1))\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test = np.asarray(y_test).reshape((len(y_test), 1))\n",
    "\n",
    "X_train = np.c_[np.ones((len(X_train), 1)), X_train]\n",
    "X_test = np.c_[np.ones((len(X_test), 1)), X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_path_mgd = []\n",
    "best_thetas = []\n",
    "m = len(X_train)\n",
    "eta = 0.1\n",
    "n_iterations = 100\n",
    "minibatch_size = [50, 2000, 10000]\n",
    "\n",
    "np.random.seed(42)\n",
    "theta = np.random.randn(3, 1)  # random initialization\n",
    "\n",
    "for size in minibatch_size:\n",
    "    for epoch in range(n_iterations):\n",
    "        shuffled_indices = np.random.permutation(m)\n",
    "        X_b_shuffled = X_train[shuffled_indices]\n",
    "        y_shuffled = y_train[shuffled_indices]\n",
    "        for i in range(0, m, size):\n",
    "            xi = X_b_shuffled[i:i + size]\n",
    "            yi = y_shuffled[i:i + size]\n",
    "            gradients = 2 / size * xi.T.dot(xi.dot(theta) - yi)\n",
    "            theta = theta - eta * gradients\n",
    "            theta_path_mgd.append(theta)\n",
    "    best_thetas.append(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatch size: 50\n",
      "Coefficients: [[10.84495525]\n",
      " [ 1.45452721]\n",
      " [-6.04653521]]\n",
      "\n",
      "\n",
      "Holdout mean squared error: 0.23\n",
      "Holdout explained variance: 0.99\n",
      "Holdout r-squared: 0.99\n",
      "\n",
      "\n",
      "minibatch size: 2000\n",
      "Coefficients: [[10.83836563]\n",
      " [ 1.36951838]\n",
      " [-5.98466765]]\n",
      "\n",
      "\n",
      "Holdout mean squared error: 0.23\n",
      "Holdout explained variance: 0.99\n",
      "Holdout r-squared: 0.99\n",
      "\n",
      "\n",
      "minibatch size: 10000\n",
      "Coefficients: [[10.85797046]\n",
      " [-0.59057347]\n",
      " [-0.42558493]]\n",
      "\n",
      "\n",
      "Holdout mean squared error: 13.14\n",
      "Holdout explained variance: 0.26\n",
      "Holdout r-squared: 0.26\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(best_thetas)):\n",
    "    print(f'minibatch size: {minibatch_size[i]}')\n",
    "    print(f'Coefficients: {best_thetas[i]}')\n",
    "    print(\"\\n\")\n",
    "    print(\"Holdout mean squared error: %.2f\"\n",
    "          % metrics.mean_squared_error(y_test, X_test.dot(best_thetas[i])))\n",
    "    print(\"Holdout explained variance: %.2f\"\n",
    "          % metrics.explained_variance_score(y_test, X_test.dot(best_thetas[\n",
    "                                                                    i])))\n",
    "    print(\"Holdout r-squared: %.2f\" % metrics.r2_score(y_test,\n",
    "                                                       X_test.dot(\n",
    "                                                           best_thetas[i])))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
