{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AAyMcULBtkU2"
   },
   "source": [
    "# Recurrent Neural Network & Classification: \n",
    "The objective is to detect the security breach by predicting suspicious access using an RNN model and the provided Logfile data.\n",
    "\n",
    "Logfile data includes login information like LogID, Timestamp, Method, Path, Status Code, Source, Remote Address, User Agent etc. The last indicator in each row denotes breach(1) and no breach(0) which is the target variable.\n",
    "\n",
    "The expectation is that you will use the keras package to solve this problem (https://keras.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TsWXrcnDtkU5"
   },
   "source": [
    "# 1. Data Processing: \n",
    "This data set is a bit messy, so the preprocessing portion is largely a tutorial to make sure students have data ready for keras. \n",
    "\n",
    "a) Import the following libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1830,
     "status": "ok",
     "timestamp": 1543532608795,
     "user": {
      "displayName": "Joshua Goldberg",
      "photoUrl": "https://lh5.googleusercontent.com/-H1ULDNmDbco/AAAAAAAAAAI/AAAAAAAAAA4/jCI2sYicxV0/s64/photo.jpg",
      "userId": "06161810390386805416"
     },
     "user_tz": 360
    },
    "id": "7ipsWmGjtkU7",
    "outputId": "23956a44-1f18-4bd5-96ce-e1157995b079"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import numpy\n",
    "import optparse\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import backend as k\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9MlI-Sh3tkVE"
   },
   "source": [
    "*b*) We will read the code in slightly differently than before: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eg6WWP_ttkVG"
   },
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"https://canvas.uchicago.edu/courses/17447/files/1909483/download?verifier=QpuhYSiinG7g0BJhPyc5oP1gwKr0nc0xg8tD6q9Z&wrap=1\", engine='python', quotechar='|', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8qbLoLbytkVJ"
   },
   "source": [
    "c) We then need to convert to a `numpy.ndarray` type: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sck2YhqItkVK"
   },
   "outputs": [],
   "source": [
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tXAs0RJQtkVN"
   },
   "source": [
    "d) Check the shape of the data set - it should be (26773, 2). Spend some time looking at the data. \n",
    "\n",
    "e) Store all rows and the 0th index as the feature data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtncvfVWtkVN"
   },
   "outputs": [],
   "source": [
    "X = dataset[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BG-XZd8btkVQ"
   },
   "source": [
    "f) Store all rows and index 1 as the target variable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwMqP9yMtkVR"
   },
   "outputs": [],
   "source": [
    "Y = dataset[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wuY4hCdUtkVT"
   },
   "source": [
    "g) In the next step, we will clean up the predictors. This includes removing features that are not valuable, such as timestamp and source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHNyZQYHtkVU"
   },
   "outputs": [],
   "source": [
    "for index, item in enumerate(X):\n",
    "    # Quick hack to space out json elements\n",
    "    reqJson = json.loads(item, object_pairs_hook=OrderedDict)\n",
    "    del reqJson['timestamp']\n",
    "    del reqJson['headers']\n",
    "    del reqJson['source']\n",
    "    del reqJson['route']\n",
    "    del reqJson['responsePayload']\n",
    "    X[index] = json.dumps(reqJson, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klOD9oVNtkVV"
   },
   "source": [
    "h) We next will tokenize our data, which just means vectorizing our text. Given the data we will tokenize every character (thus char_level = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-H3oRQVtkVW"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='\\t\\n', char_level=True)\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# we will need this later\n",
    "num_words = len(tokenizer.word_index) + 1\n",
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wRUgiLRTtkVY"
   },
   "source": [
    "i) Need to pad our data as each observation has a different length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gy0qCQWvtkVY"
   },
   "outputs": [],
   "source": [
    "max_log_length = 1024\n",
    "X_processed = sequence.pad_sequences(X, maxlen=max_log_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFPYUwjytkVa"
   },
   "source": [
    "j) Create your train set to be 75% of the data and your test set to be 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKWTCSqMtkVa"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_processed, Y, test_size=.25,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7pW6ve9XtkVc"
   },
   "source": [
    "# 2. Model 1 - RNN: \n",
    "The first model will be a pretty minimal RNN with only an embedding layer, LSTM layer, and Dense layer. The next model we will add a few more layers.\n",
    "\n",
    "a) Start by creating an instance of a Sequential model: https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpkxYOMctkVc"
   },
   "outputs": [],
   "source": [
    "k.clear_session()\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G9BCgJLAtkVd"
   },
   "source": [
    "b) From there, add an Embedding layer: https://keras.io/layers/embeddings/\n",
    "\n",
    "Params:\n",
    "- input_dim = num_words (the variable we created above)\n",
    "- output_dim = 32\n",
    "- input_length = max_log_length (we also created this above) \n",
    "- Keep all other variables as the defaults (shown below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AnIDRLxtkVe"
   },
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim=num_words, output_dim=32, input_length=max_log_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqyDGeRdtkVg"
   },
   "source": [
    "c) Add an LSTM layer https://keras.io/layers/recurrent/#lstm\n",
    "\n",
    "Params:\n",
    "- units = 64\n",
    "- recurrent_dropout=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rHfk5NBtkVh"
   },
   "outputs": [],
   "source": [
    "model.add(LSTM(units=64, recurrent_dropout=.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NADdt4mNtkVi"
   },
   "source": [
    "d) Finally, we will add a Dense layer: https://keras.io/layers/core/#dense \n",
    "\n",
    "Params:\n",
    "- units = 1 (this will be our output)\n",
    "- activation = relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1gndoGQJtkVj"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGCbVihUtkVk"
   },
   "source": [
    "e) Compile model using the .compile() method: https://keras.io/models/model/\n",
    "\n",
    "Params:\n",
    "- loss = binary_crossentropy\n",
    "- optimizer = adam\n",
    "- metrics = accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pG6tz7PktkVl"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_44s56-tkVm"
   },
   "source": [
    "Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1543532698834,
     "user": {
      "displayName": "Joshua Goldberg",
      "photoUrl": "https://lh5.googleusercontent.com/-H1ULDNmDbco/AAAAAAAAAAI/AAAAAAAAAA4/jCI2sYicxV0/s64/photo.jpg",
      "userId": "06161810390386805416"
     },
     "user_tz": 360
    },
    "id": "cREEdmYrtkVm",
    "outputId": "eb1801f8-f1e5-4f2b-bc29-0300f13325e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1024, 32)          2016      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 26,913\n",
      "Trainable params: 26,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HU9WwrzStkVp"
   },
   "source": [
    "g) Use the `.fit()` method to fit the model on the train data. Use `validation_split=0.25`, `epochs=3` `batch_size=128`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 645170,
     "status": "ok",
     "timestamp": 1543533346682,
     "user": {
      "displayName": "Joshua Goldberg",
      "photoUrl": "https://lh5.googleusercontent.com/-H1ULDNmDbco/AAAAAAAAAAI/AAAAAAAAAA4/jCI2sYicxV0/s64/photo.jpg",
      "userId": "06161810390386805416"
     },
     "user_tz": 360
    },
    "id": "9-NfaxyotkVp",
    "outputId": "4883e6ed-b164-4c75-ca5c-177f58e0674e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15059 samples, validate on 5020 samples\n",
      "Epoch 1/3\n",
      "15059/15059 [==============================] - 217s 14ms/step - loss: 0.8603 - acc: 0.5429 - val_loss: 0.6182 - val_acc: 0.6373\n",
      "Epoch 2/3\n",
      "15059/15059 [==============================] - 214s 14ms/step - loss: 0.5941 - acc: 0.6071 - val_loss: 0.5662 - val_acc: 0.5851\n",
      "Epoch 3/3\n",
      "15059/15059 [==============================] - 213s 14ms/step - loss: 0.6560 - acc: 0.5514 - val_loss: 1.1654 - val_acc: 0.4546\n"
     ]
    }
   ],
   "source": [
    "model_1_fit = model.fit(X_train, Y_train, validation_split=.25, epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJBzs1o7tkVs"
   },
   "source": [
    "h) Use the `.evaluate()` method to get the loss value & the accuracy value on the test data. Use a batch size of 128 again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 579015,
     "status": "ok",
     "timestamp": 1543533366555,
     "user": {
      "displayName": "Joshua Goldberg",
      "photoUrl": "https://lh5.googleusercontent.com/-H1ULDNmDbco/AAAAAAAAAAI/AAAAAAAAAA4/jCI2sYicxV0/s64/photo.jpg",
      "userId": "06161810390386805416"
     },
     "user_tz": 360
    },
    "id": "_pIOzu2OtkVu",
    "outputId": "4a44e94e-5918-44dc-a9b2-53a13609cdc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6694/6694 [==============================] - 20s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1093023050568658, 0.4720645353603192]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dr09w42ztkVw"
   },
   "source": [
    "# 3) Model 2 - RNN + Dropout Layers + New Activation Function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uG-CSXaMtkVw"
   },
   "source": [
    "Now we will add a few new layers to our RNN and switch the activation function. You will be creating a new model here, so make sure to call it something different than the model from Part 2.\n",
    "\n",
    "a) This RNN needs to have the following layers (add in this order):\n",
    "\n",
    "- Embedding Layer (use same params as before)\n",
    "- Dropout Layer (https://keras.io/layers/core/#dropout - use a value of 0.5 for now\n",
    "- LSTM Layer (use same params as before)\n",
    "- Dropout Layer - use a value of 0.5 \n",
    "- Dense Layer - (switch to a sigmoid activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 854,
     "status": "ok",
     "timestamp": 1543533417439,
     "user": {
      "displayName": "Joshua Goldberg",
      "photoUrl": "https://lh5.googleusercontent.com/-H1ULDNmDbco/AAAAAAAAAAI/AAAAAAAAAA4/jCI2sYicxV0/s64/photo.jpg",
      "userId": "06161810390386805416"
     },
     "user_tz": 360
    },
    "id": "6fLDmjuqtkVx",
    "outputId": "84d743ea-f208-4d4c-cefe-7e1008263088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1024, 32)          2016      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 26,913\n",
      "Trainable params: 26,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "k.clear_session()\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(num_words, 32, input_length=max_log_length))\n",
    "model2.add(LSTM(64, recurrent_dropout=0.5))\n",
    "model2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model2.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 640039,
     "status": "ok",
     "timestamp": 1543534111943,
     "user": {
      "displayName": "Joshua Goldberg",
      "photoUrl": "https://lh5.googleusercontent.com/-H1ULDNmDbco/AAAAAAAAAAI/AAAAAAAAAA4/jCI2sYicxV0/s64/photo.jpg",
      "userId": "06161810390386805416"
     },
     "user_tz": 360
    },
    "id": "m-8vJOG2wyeb",
    "outputId": "83dfadbb-c126-44c9-a828-04730423d8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15059 samples, validate on 5020 samples\n",
      "Epoch 1/3\n",
      "15059/15059 [==============================] - 214s 14ms/step - loss: 0.5970 - acc: 0.6700 - val_loss: 0.3879 - val_acc: 0.8504\n",
      "Epoch 2/3\n",
      "15059/15059 [==============================] - 213s 14ms/step - loss: 0.3815 - acc: 0.8561 - val_loss: 0.2240 - val_acc: 0.9516\n",
      "Epoch 3/3\n",
      "15059/15059 [==============================] - 212s 14ms/step - loss: 0.3347 - acc: 0.8775 - val_loss: 0.3430 - val_acc: 0.8635\n"
     ]
    }
   ],
   "source": [
    "model_2_fit = model2.fit(X_train, Y_train, epochs=3, batch_size=128,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19658,
     "status": "ok",
     "timestamp": 1543534148237,
     "user": {
      "displayName": "Joshua Goldberg",
      "photoUrl": "https://lh5.googleusercontent.com/-H1ULDNmDbco/AAAAAAAAAAI/AAAAAAAAAA4/jCI2sYicxV0/s64/photo.jpg",
      "userId": "06161810390386805416"
     },
     "user_tz": 360
    },
    "id": "A7fclaKMw8GF",
    "outputId": "644da393-aeec-4459-b13d-87ba652dc7ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6694/6694 [==============================] - 19s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34538009765435235, 0.8624141021098242]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test, Y_test, batch_size=128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDKdxaDyxMmU"
   },
   "source": [
    "# 4) Recurrent Neural Net Model 3: Build Your Own\n",
    "a) RNN Requirements: \n",
    "- Use 5 or more layers\n",
    "- Add a layer that was not utilized in Model 1 or Model 2 (Note: This could be a new Dense layer or an additional LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1262,
     "status": "ok",
     "timestamp": 1543534157548,
     "user": {
      "displayName": "Joshua Goldberg",
      "photoUrl": "https://lh5.googleusercontent.com/-H1ULDNmDbco/AAAAAAAAAAI/AAAAAAAAAA4/jCI2sYicxV0/s64/photo.jpg",
      "userId": "06161810390386805416"
     },
     "user_tz": 360
    },
    "id": "Pq-dc60qxFXn",
    "outputId": "27c1f92f-2649-4cc9-9cdd-1615d3238fae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1024, 32)          2016      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1024, 64)          24832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 59,937\n",
      "Trainable params: 59,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "k.clear_session()\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(num_words, 32, input_length=max_log_length))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(LSTM(64,recurrent_dropout=0.5,return_sequences= True))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(LSTM(64, recurrent_dropout=0.5))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model3.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=['acc'])\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1605504,
     "status": "ok",
     "timestamp": 1543535766709,
     "user": {
      "displayName": "Joshua Goldberg",
      "photoUrl": "https://lh5.googleusercontent.com/-H1ULDNmDbco/AAAAAAAAAAI/AAAAAAAAAA4/jCI2sYicxV0/s64/photo.jpg",
      "userId": "06161810390386805416"
     },
     "user_tz": 360
    },
    "id": "WzMP9CMtxa6s",
    "outputId": "9d20ea76-b7dd-4d93-f486-cc78f0dfd408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15059 samples, validate on 5020 samples\n",
      "Epoch 1/3\n",
      "15059/15059 [==============================] - 535s 36ms/step - loss: 0.5120 - acc: 0.7423 - val_loss: 0.2572 - val_acc: 0.8918\n",
      "Epoch 2/3\n",
      "15059/15059 [==============================] - 533s 35ms/step - loss: 0.2942 - acc: 0.8950 - val_loss: 0.1373 - val_acc: 0.9588\n",
      "Epoch 3/3\n",
      "15059/15059 [==============================] - 535s 35ms/step - loss: 0.1966 - acc: 0.9426 - val_loss: 0.0930 - val_acc: 0.9775\n"
     ]
    }
   ],
   "source": [
    "model_3_fit = model3.fit(X_train, Y_train, epochs=3, batch_size=128, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53779,
     "status": "ok",
     "timestamp": 1543535942481,
     "user": {
      "displayName": "Joshua Goldberg",
      "photoUrl": "https://lh5.googleusercontent.com/-H1ULDNmDbco/AAAAAAAAAAI/AAAAAAAAAA4/jCI2sYicxV0/s64/photo.jpg",
      "userId": "06161810390386805416"
     },
     "user_tz": 360
    },
    "id": "aEUd1siExc2A",
    "outputId": "03811d43-6a01-471f-ce88-034cf5e1c519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6694/6694 [==============================] - 53s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09791403422969684, 0.9763967733544167]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test, Y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YzqsvyhCxucN"
   },
   "source": [
    "# Conceptual Questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_jlPq6EpxyD3"
   },
   "source": [
    "# 5) Explain the difference between the relu activation function and the sigmoid activation function. \n",
    "\n",
    "__rectified linear unit  (ReLU)__, defined as: $f(x)=x^{+}=\\max(0,x)$, is an activation function with strong biological motivation. \n",
    "\n",
    "ReLU's biggest advantage is it's efficiency: since it does not activate all neurons at the same time, it is very fast. This is largely driven by ReLU's behavior to convert inputs to zero if negative, which leads to a sparse matrix. ReLU also has fewer vanishing gradients than sigmoid, but problems can occur which I highlight below. \n",
    "\n",
    "Drawbacks: ReLU is the dying ReLU problem. In this state, neurons become 'stuck' and inactive for all inputs (sometimes referred to as 'dying'). If too many neurons become stuck in this dead state, the model can become extremely ineffective. There are methods to mitigating this problem, including __Leaky ReLUs__, which allow a small, positive gradient when the unit is not active, or a smaller learning rate. In addition to dying neurons, the ReLU function is also non-differentiable at zero.\n",
    "\n",
    "__sigmoid__ defined as: $S(x)={\\frac{1}{1+e^{-x}}}={\\frac{e^{x}}{e^{x}+1}}$\n",
    "\n",
    "The sigmoid function is bounded between (0, 1), so it is used for typical binary classification problems. It is also differentiable at any point. The bounded nature of the sigmoid creates a weakness: _vanishing gradients_, where gradients drop close to zero and the model capacity typically falls short of acceptable. For inputs close to 0 or 1, the gradient with respect to those inputs are close to zero. where gradients drop close to zero, and the net does not learn well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sa5x4Lan6JUR"
   },
   "source": [
    "# 6) In regards to question 5, which of these activation functions performed the best (they were used in Model 1 & Model 2) ? Why do you think that is?\n",
    "\n",
    "The sigmoid function performed much better than ReLU, which may be driven by sigmoid's ability to shift the result based on values of x near the center of the function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "igwNLJKE-j7s"
   },
   "source": [
    "# 7) Explain how dropout works (you can look at the keras code) for (a) training, and (b) test data sets.\n",
    "\n",
    "(a) Dropout is a regularization technique used to prevent overfitting. During training, randomly selected neurons are ignored ('dropped out'). This leads to a better generalization error, since the neural network will be less sensitive to specific neuron weights.\n",
    "\n",
    "(b) Dropout only applies to training. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfvT6638_sK9"
   },
   "source": [
    "# 8) Explain why problems such as this are better modeled with RNNs than CNNs.\n",
    "\n",
    "This problem involves time-series data. We have inputs from a log file. RNNs are typically used with problems of this nature, given that they have memory that can serve as feedback loops. RNN also can be fed data of different lengths, while CNN require fixed input. In in this case, we have time-series data without consistent lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LsJNrHahAmye"
   },
   "source": [
    "# 9) Explain what RNN problem is solved using LSTM and briefly describe how.\n",
    "\n",
    "Recurrent neural networks (RNN) has a problem of long-term dependencies. While RNN was created with the idea of connecting previous information to present tasks, there are situations where more context is needed to make a reasonable prediction of the present tasks. This gap between relevant information and the present task can grow, leading to poor performance by RNN. \n",
    "\n",
    "This problem of long-term dependencies is solved with Long Short Term Memory networks (LSTM), a special kind of RNN. LSTMs expand the chain structure found in RNNs to include four additional layers within each chain. These layers are much more complex than a simple RNN, and give LSTM the ability to add or remove information with gates. Gates are comprised of of a sigmoid neural net layer and a pointwise multiplication operation. The sigmoid layer outputs a 0 or 1 (0 disallows; 1 allows)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 7 Joshua Goldberg.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
