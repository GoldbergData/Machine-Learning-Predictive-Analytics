{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network & Classification: \n",
    "\n",
    "The objective is to build an image classifier that is capable of properly identifying four different categories of image. \n",
    "\n",
    "The data consists of various train and test samples across the four categories of image. You will notice that the data for a specific category is a singular image that has been flipped, rotated, or slightly altered in some way. \n",
    "\n",
    "You can use the keras package to solve this problem (https://keras.io/)\n",
    "\n",
    "## 1. Data Processing: \n",
    "\n",
    "The train & test data is pretty clean in terms of image data, but we will need to do a bit of prep work to use in our model. \n",
    "\n",
    "a) Use the `ImageDataGenerator()` class from `keras.preprocessing.image` to build out an instance called `train_datagen` with the following parameters: \n",
    "\n",
    "* rescale = 1./255\n",
    "\n",
    "* shear_range = 0.2\n",
    "\n",
    "* zoom_range = 0.2\n",
    "\n",
    "* horizontal_flip = True\n",
    "\n",
    "b) Then build your training set by using the method `.flow_from_directory()`\n",
    "\n",
    "* path (where training data is stored)\n",
    "* target_size = (64, 64)\n",
    "* batch_size = 32\n",
    "* class_mode = categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image as ki\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Conv2D, Flatten\n",
    "from keras.layers import LSTM, Dense, Dropout, MaxPooling2D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import backend as k\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ki.ImageDataGenerator(rescale=1/255, shear_range=.2, \n",
    "                                      zoom_range=.2, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = train_datagen.flow_from_directory(\"./dataset_train/\", target_size=(64, 64),\n",
    "                                 batch_size=32, class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Take a look at your training set: \n",
    "\n",
    "What is the image shape of each training observation? Very strange shapes; some crosses, a skull, or letters maybe.\n",
    "\n",
    "How many total classes do we need to predict on? 4 classes, according to the output of `train_datagen.flow_from_directory`.\n",
    "\n",
    "2. Initial Classifier Build: Now use `keras` to build an initial image classifier with the following specifications.\n",
    "\n",
    "Note: If you get lost, there is great documentation online and homework 7 included details on many of the layers used here.\n",
    "\n",
    "Create an instance of `Sequential` called `classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.clear_session()\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add a `Conv2D` layer with the following parameters: \n",
    "\n",
    "    * filters = 32\n",
    "\n",
    "    * kernel_size = (3,3)\n",
    "\n",
    "    * input_shape = image shape found in part 1\n",
    "\n",
    "    * activation = relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                input_shape=(64, 64, 3), activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add a `MaxPooling2D` layer where pool_size = (2,2)\n",
    "* Add a Flatten layer\n",
    "* Add a Dense layer\n",
    "    * units = 128\n",
    "    * activation = relu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add a final Dense layer (this will output our probabilities):\n",
    "    * units = # of classes\n",
    "    \n",
    "    * activation = softmax \n",
    "    \n",
    "* Compile with the following: \n",
    "\n",
    "    * optimize = adam\n",
    "    \n",
    "    * loss = categorical cross entropy\n",
    "    \n",
    "    * metric = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 30752)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3936384   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 3,937,816\n",
      "Trainable params: 3,937,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(units=4, activation=\"softmax\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __Model Runs__: This will run various times with different numbers of steps_per_epoch and epochs. \n",
    "\n",
    "a) Use `.fit_generator()` with the training set. For the first run, use the following parameters: \n",
    "\n",
    "* steps_per_epoch = 10\n",
    "\n",
    "* epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 2.5429 - acc: 0.4918\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4509 - acc: 0.8803\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.2062 - acc: 0.9688\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.1233 - acc: 0.9865\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.0778 - acc: 0.9824\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.0648 - acc: 0.9814\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.0388 - acc: 0.9896\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.0200 - acc: 0.9968\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.0101 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit_generator(train_datagen, steps_per_epoch=10, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Write out each model & `model_weights` to a file. An example is below:\n",
    "\n",
    "```python\n",
    "# write model and model weights to disk\n",
    "model_yaml = classifier.to_yaml()\n",
    "with open(\"model_1.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "    classifier.save_weights(\"model_1.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# write model and model weights to disk\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model_1.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "    model.save_weights(\"model_1.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Predict using the model built in step 2. An example below shows how to reread weights & model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([1])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "from keras.models import model_from_yaml\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Load model from disk\n",
    "yaml_file = open(\"model_4.yaml\", \"r\")\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "model = model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "# Load weights into new model\n",
    "model.load_weights(\"model_4.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# Test data path\n",
    "img_dir = \"./dataset_test\" # Enter Directory of all images\n",
    "\n",
    "# Iterate over each test image\n",
    "# Make a prediction and add to results \n",
    "data_path = os.path.join(img_dir, \"*g\")\n",
    "files = glob.glob(data_path)\n",
    "data = []\n",
    "results = []\n",
    "\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result = model.predict(img)\n",
    "    r = np.argmax(result, axis=1)\n",
    "    results.append(r)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Determine accuracy.\n",
    "\n",
    "Note: To determine accuracy, you will need to manually check the labels given to each class in the training data. This will require you to go and look in the training data, and then determine how a category was coded in `keras`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 25.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual_label_list = [0, 0, 2, 2, 1, 1, 3, 3]\n",
    "predicted = [a for r in results for a in r]\n",
    "actual_label_list == predicted\n",
    "accuracy = len([i for i, j in zip(actual_label_list, predicted) if i == j]) / len(actual_label_list)\n",
    "print(f\"Model accuracy: {accuracy * 100}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you do this, you will need to compare predicted values to the actual values for the test set (there are only 8 test observations). \n",
    "\n",
    "e) Run this process for the following combinations:\n",
    "\n",
    "* (steps_per_epoch: 10, epochs: 10) <- the one we just did \n",
    "\n",
    "* (steps_per_epoch: 10, epochs: 20)\n",
    "\n",
    "* (steps_per_epoch: 10, epochs: 30)\n",
    "\n",
    "* (steps_per_epoch: 30, epochs: 10)\n",
    "\n",
    "* (steps_per_epoch: 30, epochs: 20)\n",
    "\n",
    "* (steps_per_epoch: 30, epochs: 30)\n",
    "\n",
    "* (steps_per_epoch: 50, epochs: 10)\n",
    "\n",
    "* (steps_per_epoch: 50, epochs: 20)\n",
    "\n",
    "* (steps_per_epoch: 50, epochs: 30)\n",
    "\n",
    "* (steps_per_epoch: 50, epochs: 100) (Please note: This one will take some time so you should consider running and saving the model outputs so you don't have to keep an eye on your code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# http://danshiebler.com/2016-09-14-parallel-progress-bar/\n",
    "def parallel_process(array, function, n_jobs=8, use_kwargs=False, front_num=3):\n",
    "    \"\"\"\n",
    "        A parallel version of the map function with a progress bar. \n",
    "\n",
    "        Args:\n",
    "            array (array-like): An array to iterate over.\n",
    "            function (function): A python function to apply to the elements of array\n",
    "            n_jobs (int, default=16): The number of cores to use\n",
    "            use_kwargs (boolean, default=False): Whether to consider the elements of array as dictionaries of \n",
    "                keyword arguments to function \n",
    "            front_num (int, default=3): The number of iterations to run serially before kicking off the parallel job. \n",
    "                Useful for catching bugs\n",
    "        Returns:\n",
    "            [function(array[0]), function(array[1]), ...]\n",
    "    \"\"\"\n",
    "    # We run the first few iterations serially to catch bugs\n",
    "    if front_num > 0:\n",
    "        front = [function(**a) if use_kwargs else function(a) for a in array[:front_num]]\n",
    "    # If we set n_jobs to 1, just run a list comprehension. This is useful for benchmarking and debugging.\n",
    "    if n_jobs==1:\n",
    "        return front + [function(**a) if use_kwargs else function(a) for a in tqdm(array[front_num:])]\n",
    "    # Assemble the workers\n",
    "    with ProcessPoolExecutor(max_workers=n_jobs) as pool:\n",
    "        # Pass the elements of array into function\n",
    "        if use_kwargs:\n",
    "            futures = [pool.submit(function, **a) for a in array[front_num:]]\n",
    "        else:\n",
    "            futures = [pool.submit(function, a) for a in array[front_num:]]\n",
    "        kwargs = {\n",
    "            'total': len(futures),\n",
    "            'unit': 'it',\n",
    "            'unit_scale': True,\n",
    "            'leave': True\n",
    "        }\n",
    "        # Print out the progress as tasks complete\n",
    "        for f in tqdm(as_completed(futures), **kwargs):\n",
    "            pass\n",
    "    out = []\n",
    "    # Get the results from the futures. \n",
    "    for i, future in tqdm(enumerate(futures)):\n",
    "        try:\n",
    "            out.append(future.result())\n",
    "        except Exception as e:\n",
    "            out.append(e)\n",
    "    return front + out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0,
     11,
     43,
     49
    ]
   },
   "outputs": [],
   "source": [
    "def fit_model(params):\n",
    "    print(f\"Fitting model: {params}\")\n",
    "    model_fit = model.fit_generator(train_datagen, steps_per_epoch=params[\"steps_per_epoch\"], epochs=params[\"epochs\"])\n",
    "    # write model and model weights to disk\n",
    "    model_yaml = model.to_yaml()\n",
    "    model_name = params[\"model_name\"]\n",
    "    with open(f\"{model_name}.yaml\", \"w\") as yaml_file:\n",
    "        yaml_file.write(model_yaml)\n",
    "        model.save_weights(f\"{model_name}.h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "\n",
    "def predict_image(model_name):\n",
    "    # Load model from disk\n",
    "    yaml_file = open(f\"{model_name}.yaml\", \"r\")\n",
    "    loaded_model_yaml = yaml_file.read()\n",
    "    yaml_file.close()\n",
    "    model = model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "    # Load weights into new model\n",
    "    model.load_weights(f\"{model_name}.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "    # Test data path\n",
    "    img_dir = \"./dataset_test\" # Enter Directory of all images\n",
    "\n",
    "    # Iterate over each test image\n",
    "    # Make a prediction and add to results \n",
    "    data_path = os.path.join(img_dir, \"*g\")\n",
    "    files = glob.glob(data_path)\n",
    "    data = []\n",
    "    results = []\n",
    "\n",
    "    for f1 in files:\n",
    "        img = image.load_img(f1, target_size = (64, 64))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "        data.append(img)\n",
    "        result = model.predict(img)\n",
    "        r = np.argmax(result, axis=1)\n",
    "        results.append(r)\n",
    "\n",
    "    return(results)\n",
    "\n",
    "def model_accuracy(result):\n",
    "    actual_label_list = [0, 0, 2, 2, 1, 1, 3, 3]\n",
    "    predicted = [a for r in results for a in r]\n",
    "    accuracy = len([i for i, j in zip(actual_label_list, predicted) if i == j]) / len(actual_label_list)\n",
    "    return(accuracy)\n",
    "\n",
    "def run_model(params):\n",
    "    model_name = params[\"model_name\"]\n",
    "    fit_model(params)\n",
    "    result = predict_image(model_name)\n",
    "    return(model_accuracy(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{\"steps_per_epoch\": 10, \"epochs\": 10, \"model_name\": \"model_1\"},\n",
    " {\"steps_per_epoch\": 10, \"epochs\": 20, \"model_name\": \"model_2\"},\n",
    " {\"steps_per_epoch\": 10, \"epochs\": 30, \"model_name\": \"model_3\"},\n",
    " {\"steps_per_epoch\": 30, \"epochs\": 10, \"model_name\": \"model_4\"},\n",
    " {\"steps_per_epoch\": 30, \"epochs\": 20, \"model_name\": \"model_5\"},\n",
    " {\"steps_per_epoch\": 30, \"epochs\": 30, \"model_name\": \"model_6\"},\n",
    " {\"steps_per_epoch\": 50, \"epochs\": 10, \"model_name\": \"model_7\"},\n",
    " {\"steps_per_epoch\": 50, \"epochs\": 20, \"model_name\": \"model_8\"},\n",
    " {\"steps_per_epoch\": 50, \"epochs\": 30, \"model_name\": \"model_9\"},\n",
    " {\"steps_per_epoch\": 50, \"epochs\": 100, \"model_name\": \"model_10\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 30752)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3936384   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 3,937,816\n",
      "Trainable params: 3,937,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model: {'steps_per_epoch': 10, 'epochs': 10, 'model_name': 'model_1'}\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 1.1457 - acc: 0.4242\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 1.0840 - acc: 0.4956\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 1.0713 - acc: 0.5041\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 1.0616 - acc: 0.4997\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 1.0479 - acc: 0.5028\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 1.0340 - acc: 0.4858\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 1.0180 - acc: 0.5044\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 1.0080 - acc: 0.4928\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.9998 - acc: 0.5098\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.9919 - acc: 0.5335\n",
      "Saved model to disk\n",
      "Loaded model from disk\n",
      "Fitting model: {'steps_per_epoch': 10, 'epochs': 20, 'model_name': 'model_2'}\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.9840 - acc: 0.7491\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.9757 - acc: 0.7121\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.9598 - acc: 0.7387\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.9531 - acc: 0.7531\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.9410 - acc: 0.7522\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.9325 - acc: 0.7557\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.9282 - acc: 0.7355\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.9228 - acc: 0.7446\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.9097 - acc: 0.7437\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.8995 - acc: 0.7638\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.8958 - acc: 0.7339\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8901 - acc: 0.7333\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.8772 - acc: 0.7569\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.8673 - acc: 0.7569\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.8633 - acc: 0.7560\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.8548 - acc: 0.7412\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.8512 - acc: 0.7547\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.8418 - acc: 0.7604\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.8408 - acc: 0.7494\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.8288 - acc: 0.7506\n",
      "Saved model to disk\n",
      "Loaded model from disk\n",
      "Fitting model: {'steps_per_epoch': 10, 'epochs': 30, 'model_name': 'model_3'}\n",
      "Epoch 1/30\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.8209 - acc: 0.7572\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.8110 - acc: 0.7620\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.8131 - acc: 0.7437\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 0.8073 - acc: 0.7516\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8007 - acc: 0.7345\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.7904 - acc: 0.7500\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.7882 - acc: 0.7576\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.7835 - acc: 0.7336\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7769 - acc: 0.7324\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.7590 - acc: 0.8731\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 0.7521 - acc: 0.9937\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 0.7352 - acc: 1.0000\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.7220 - acc: 1.0000\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.7060 - acc: 1.0000\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.6921 - acc: 1.0000\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 3s 264ms/step - loss: 0.6757 - acc: 1.0000\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.6627 - acc: 1.0000\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.6501 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.6398 - acc: 1.0000\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.6241 - acc: 1.0000\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.6172 - acc: 1.0000\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.6021 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.5980 - acc: 1.0000\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.5900 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.5727 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.5716 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.5578 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.5522 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.5423 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.5361 - acc: 1.0000\n",
      "Saved model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Fitting model: {'steps_per_epoch': 30, 'epochs': 10, 'model_name': 'model_4'}\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 9s 291ms/step - loss: 0.5188 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 8s 274ms/step - loss: 0.4977 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 9s 297ms/step - loss: 0.4773 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 8s 259ms/step - loss: 0.4581 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 9s 286ms/step - loss: 0.4410 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 8s 275ms/step - loss: 0.4236 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 9s 300ms/step - loss: 0.4089 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 9s 299ms/step - loss: 0.3926 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 9s 292ms/step - loss: 0.3777 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 9s 295ms/step - loss: 0.3654 - acc: 1.0000\n",
      "Saved model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [01:26<08:39, 86.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Fitting model: {'steps_per_epoch': 30, 'epochs': 20, 'model_name': 'model_5'}\n",
      "Epoch 1/20\n",
      "30/30 [==============================] - 8s 279ms/step - loss: 0.3520 - acc: 1.0000\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 9s 299ms/step - loss: 0.3394 - acc: 1.0000\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 9s 295ms/step - loss: 0.3279 - acc: 1.0000\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 9s 295ms/step - loss: 0.3168 - acc: 1.0000\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 9s 308ms/step - loss: 0.3066 - acc: 1.0000\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 9s 310ms/step - loss: 0.2961 - acc: 1.0000\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 11s 369ms/step - loss: 0.2866 - acc: 1.0000\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 9s 302ms/step - loss: 0.2770 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 9s 300ms/step - loss: 0.2681 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 9s 313ms/step - loss: 0.2594 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 10s 325ms/step - loss: 0.2515 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 9s 296ms/step - loss: 0.2437 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 9s 290ms/step - loss: 0.2363 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 8s 269ms/step - loss: 0.2290 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 8s 278ms/step - loss: 0.2221 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 8s 257ms/step - loss: 0.2157 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 8s 278ms/step - loss: 0.2092 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 9s 294ms/step - loss: 0.2030 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 9s 291ms/step - loss: 0.1974 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 9s 307ms/step - loss: 0.1915 - acc: 1.0000\n",
      "Saved model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▊       | 2/7 [04:25<09:31, 114.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Fitting model: {'steps_per_epoch': 30, 'epochs': 30, 'model_name': 'model_6'}\n",
      "Epoch 1/30\n",
      "30/30 [==============================] - 9s 289ms/step - loss: 0.1865 - acc: 1.0000\n",
      "Epoch 2/30\n",
      "30/30 [==============================] - 9s 311ms/step - loss: 0.1807 - acc: 1.0000\n",
      "Epoch 3/30\n",
      "30/30 [==============================] - 8s 275ms/step - loss: 0.1764 - acc: 1.0000\n",
      "Epoch 4/30\n",
      "30/30 [==============================] - 8s 275ms/step - loss: 0.1712 - acc: 1.0000\n",
      "Epoch 5/30\n",
      "30/30 [==============================] - 9s 297ms/step - loss: 0.1666 - acc: 1.0000\n",
      "Epoch 6/30\n",
      "30/30 [==============================] - 9s 287ms/step - loss: 0.1620 - acc: 1.0000\n",
      "Epoch 7/30\n",
      "30/30 [==============================] - 9s 295ms/step - loss: 0.1579 - acc: 1.0000\n",
      "Epoch 8/30\n",
      "30/30 [==============================] - 8s 282ms/step - loss: 0.1535 - acc: 1.0000\n",
      "Epoch 9/30\n",
      "30/30 [==============================] - 9s 295ms/step - loss: 0.1495 - acc: 1.0000\n",
      "Epoch 10/30\n",
      "30/30 [==============================] - 9s 293ms/step - loss: 0.1455 - acc: 1.0000\n",
      "Epoch 11/30\n",
      "30/30 [==============================] - 8s 273ms/step - loss: 0.1420 - acc: 1.0000\n",
      "Epoch 12/30\n",
      "30/30 [==============================] - 8s 269ms/step - loss: 0.1386 - acc: 1.0000\n",
      "Epoch 13/30\n",
      "30/30 [==============================] - 10s 324ms/step - loss: 0.1349 - acc: 1.0000\n",
      "Epoch 14/30\n",
      "30/30 [==============================] - 8s 272ms/step - loss: 0.1314 - acc: 1.0000\n",
      "Epoch 15/30\n",
      "30/30 [==============================] - 8s 258ms/step - loss: 0.1281 - acc: 1.0000\n",
      "Epoch 16/30\n",
      "30/30 [==============================] - 8s 271ms/step - loss: 0.1250 - acc: 1.0000\n",
      "Epoch 17/30\n",
      "30/30 [==============================] - 9s 301ms/step - loss: 0.1223 - acc: 1.0000\n",
      "Epoch 18/30\n",
      "30/30 [==============================] - 9s 299ms/step - loss: 0.1190 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "30/30 [==============================] - 9s 283ms/step - loss: 0.1159 - acc: 1.0000\n",
      "Epoch 20/30\n",
      "30/30 [==============================] - 9s 291ms/step - loss: 0.1135 - acc: 1.0000\n",
      "Epoch 21/30\n",
      "30/30 [==============================] - 9s 306ms/step - loss: 0.1106 - acc: 1.0000\n",
      "Epoch 22/30\n",
      "30/30 [==============================] - 10s 318ms/step - loss: 0.1079 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "30/30 [==============================] - 8s 273ms/step - loss: 0.1055 - acc: 1.0000\n",
      "Epoch 24/30\n",
      "30/30 [==============================] - 8s 271ms/step - loss: 0.1030 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "30/30 [==============================] - 9s 305ms/step - loss: 0.1007 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "30/30 [==============================] - 8s 277ms/step - loss: 0.0984 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "30/30 [==============================] - 8s 273ms/step - loss: 0.0963 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "30/30 [==============================] - 8s 254ms/step - loss: 0.0941 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "30/30 [==============================] - 9s 284ms/step - loss: 0.0921 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "30/30 [==============================] - 8s 278ms/step - loss: 0.0898 - acc: 1.0000\n",
      "Saved model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 3/7 [08:43<10:29, 157.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Fitting model: {'steps_per_epoch': 50, 'epochs': 10, 'model_name': 'model_7'}\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 13s 262ms/step - loss: 0.0872 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 13s 264ms/step - loss: 0.0840 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 14s 272ms/step - loss: 0.0811 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 0.0782 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 13s 270ms/step - loss: 0.0753 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 0.0729 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0703 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 0.0679 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 0.0656 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 16s 313ms/step - loss: 0.0635 - acc: 1.0000\n",
      "Saved model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████▋    | 4/7 [10:59<07:32, 150.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Fitting model: {'steps_per_epoch': 50, 'epochs': 20, 'model_name': 'model_8'}\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 15s 306ms/step - loss: 0.0613 - acc: 1.0000\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 14s 273ms/step - loss: 0.0593 - acc: 1.0000\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 13s 258ms/step - loss: 0.0573 - acc: 1.0000\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 12s 248ms/step - loss: 0.0555 - acc: 1.0000\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 14s 276ms/step - loss: 0.0537 - acc: 1.0000\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 14s 273ms/step - loss: 0.0520 - acc: 1.0000\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 0.0504 - acc: 1.0000\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 14s 273ms/step - loss: 0.0488 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 14s 274ms/step - loss: 0.0472 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 0.0459 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 14s 271ms/step - loss: 0.0430 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 14s 287ms/step - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 14s 285ms/step - loss: 0.0405 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 14s 279ms/step - loss: 0.0393 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 14s 279ms/step - loss: 0.0381 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 16s 313ms/step - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 15s 293ms/step - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 15s 299ms/step - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 16s 311ms/step - loss: 0.0338 - acc: 1.0000\n",
      "Saved model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████▏  | 5/7 [15:39<06:19, 189.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Fitting model: {'steps_per_epoch': 50, 'epochs': 30, 'model_name': 'model_9'}\n",
      "Epoch 1/30\n",
      "50/50 [==============================] - 14s 279ms/step - loss: 0.0328 - acc: 1.0000\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 14s 284ms/step - loss: 0.0319 - acc: 1.0000\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 16s 313ms/step - loss: 0.0310 - acc: 1.0000\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 16s 328ms/step - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 14s 275ms/step - loss: 0.0284 - acc: 1.0000\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 14s 275ms/step - loss: 0.0276 - acc: 1.0000\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 15s 294ms/step - loss: 0.0268 - acc: 1.0000\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 14s 279ms/step - loss: 0.0261 - acc: 1.0000\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 0.0254 - acc: 1.0000\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 14s 284ms/step - loss: 0.0247 - acc: 1.0000\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 16s 326ms/step - loss: 0.0240 - acc: 1.0000\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 14s 280ms/step - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 14s 271ms/step - loss: 0.0227 - acc: 1.0000\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 14s 276ms/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 15s 307ms/step - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 16s 314ms/step - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 0.0203 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 14s 271ms/step - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 14s 290ms/step - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 15s 291ms/step - loss: 0.0183 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 16s 311ms/step - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 15s 307ms/step - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 16s 311ms/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 14s 288ms/step - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 14s 287ms/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 14s 277ms/step - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 14s 273ms/step - loss: 0.0148 - acc: 1.0000\n",
      "Saved model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|████████▌ | 6/7 [22:56<04:23, 263.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Fitting model: {'steps_per_epoch': 50, 'epochs': 100, 'model_name': 'model_10'}\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 13s 263ms/step - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 14s 283ms/step - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 14s 287ms/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 13s 260ms/step - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 14s 275ms/step - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 14s 278ms/step - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 14s 290ms/step - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 15s 292ms/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 16s 316ms/step - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 14s 284ms/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 15s 308ms/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 15s 305ms/step - loss: 0.0108 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 16s 316ms/step - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 14s 276ms/step - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 15s 293ms/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 14s 288ms/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 14s 288ms/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 15s 309ms/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 15s 305ms/step - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 16s 320ms/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 16s 310ms/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 15s 293ms/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 15s 292ms/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 14s 290ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 14s 288ms/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 14s 289ms/step - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 15s 305ms/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 15s 293ms/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 16s 317ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 16s 323ms/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 16s 320ms/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 15s 295ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 15s 308ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 17s 336ms/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 16s 317ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 16s 325ms/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 16s 311ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 15s 307ms/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 14s 275ms/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 15s 297ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 14s 288ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 16s 323ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 15s 296ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 14s 288ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 15s 298ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 14s 275ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 14s 270ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 13s 259ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 14s 274ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 13s 263ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 14s 271ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 14s 272ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 14s 273ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 13s 265ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 14s 273ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 14s 274ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 14s 275ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 14s 274ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 14s 274ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 14s 272ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 14s 273ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 14s 273ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 14s 281ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 14s 289ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 14s 289ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 14s 280ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 13s 267ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 13s 269ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 14s 271ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 17s 341ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 14s 275ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 14s 274ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 14s 277ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 13s 265ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 14s 273ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 14s 274ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 14s 273ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 14s 273ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 14s 271ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 14s 277ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 14s 277ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 14s 279ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 17s 332ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 18s 354ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 18s 350ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 19s 380ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 15s 308ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 15s 298ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 15s 293ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 15s 293ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 15s 294ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Saved model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [47:14<00:00, 622.16s/it]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "model_grid_results = parallel_process(param_grid, run_model, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_name</th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>model_1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>model_2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>model_3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>model_4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>model_5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>model_6</td>\n",
       "      <td>30</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>model_7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>model_8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>model_9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>model_10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs model_name  steps_per_epoch  accuracy\n",
       "0      10    model_1               10      0.25\n",
       "1      20    model_2               10      0.25\n",
       "2      30    model_3               10      0.25\n",
       "3      10    model_4               30      0.25\n",
       "4      20    model_5               30      0.25\n",
       "5      30    model_6               30      0.25\n",
       "6      10    model_7               50      0.25\n",
       "7      20    model_8               50      0.25\n",
       "8      30    model_9               50      0.25\n",
       "9     100   model_10               50      0.25"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(param_grid).assign(accuracy=model_grid_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptual Questions: \n",
    "\n",
    "4. Discuss the effect of the following on accuracy and loss (train & test): \n",
    "\n",
    "    * Increasing the `steps_per_epoch`: \n",
    "\n",
    "    * Increasing the number of `epochs`: \n",
    "\n",
    "5. Name two uses of zero padding in CNN. \n",
    "\n",
    "    * Zero padding preserves information as we add more layers to the CNN.\n",
    "    \n",
    "    * Zero padding is also used to set dimensions equal to our output specifications.\n",
    "\n",
    "6. What is the use of a 1 x 1 kernel in CNN? [Stack Exchange](https://stats.stackexchange.com/questions/194142/what-does-1x1-convolution-mean-in-a-neural-network): We use the 1x1 convolutional filters to reduce dimensionality in the filter dimension. As I explained above, these 1x1 conv layers can be used in general to change the filter space dimensionality (either increase or decrease) and in the Inception architecture we see how effective these 1x1 filters can be for dimensionality reduction, explicitly in the filter dimension space, not the spatial dimension space.\n",
    "\n",
    "7. What are the advantages of a CNN over a fully connected DNN for this image classification problem? They are good at extracting features and efficiently processing images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
